{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92918799-2049-46a4-a542-2ac30086cb43",
   "metadata": {},
   "source": [
    "## 该Notebook是V13版本的OpenFISH decoding代码，openDecode的版本为V2.0 beta，特性如下：  \n",
    "\n",
    "* 接受的输入为depth后的czi文件；\n",
    "* 全程都可以在notebook内部完成 \n",
    "* 使用的包见 D:/openFISH/Decoding/openDecode\n",
    "* 主要包含图像预处理(preprocess)-图像对齐(registration)-信号点识别(spot detection)-细胞分割(segmentation)-解码(decoding)-生成表达矩阵(matrixization)五个部分\n",
    "* 以上五个部分有对应的‘代号’，可以用于跳过运行或强制运行.(具体的跳过或者强制运行命令见下)\n",
    "| Procedure | Code |\n",
    "|:---------|:---------:|\n",
    "| preprocess | 0 |\n",
    "| registration | 1 |\n",
    "| spot detection | 2 |\n",
    "| segmentation | 3 |\n",
    "| decoding | 4 |\n",
    "| matrixization | 5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ef250-587c-4260-9ba8-17d50009f01a",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93864b32-db3e-42b9-a43b-aa327458417d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>提示：</b>拍图时不要设置通道位移参数， 拍图请仔细调整曝光时间和曝光强度，避免过曝，淬灭或过暗。拍图通道选择无要求，但需保证和CodeBook一致</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>提示：</b>请至少使用景深扩展处理图像，最好不要进行拼接(到位)，这样会使图像非马赛克化(is_mosiac = False)。但是该解码程序支持非拼图(包括单张小图或拼接好的大图)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b44fe-6292-4d8c-b813-30483eb78f77",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b><h2> 1.填写参数</b></h2> \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>提示:</b>CodeBook格式如下(逗号分隔)：</div>\n",
    "支持全单色编码，全双色编码，单双色混合编码\n",
    "\n",
    "| gene | RO1 | RO2 | Round |\n",
    "|---------:|---------:|---------:|---------:|\n",
    "| Cck | AF488 | AF546 | R1 |\n",
    "| Rgs5 | AF488 | AF594 | R1 |\n",
    "| Nfib | Cy5 | Cy5 | R1 |\n",
    "| Slc17a6 | AF546 | AF546 | R4 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a81eaf24-e236-4dcf-8f8e-41ecad010276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/media/duan/DuanLab_Data/openFISH/Decode\")\n",
    "\n",
    "from openDecode_Black import OpenDecoder, config\n",
    "\n",
    "para = config.Para(\n",
    "    \n",
    "    filename = {\n",
    "        'R1': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R1_depth.czi',\n",
    "        'R2': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R2_depth.czi',\n",
    "        'R3': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R3_depth.czi',\n",
    "        'R4': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R4_depth.czi',\n",
    "        'R5': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R5_depth.czi',\n",
    "        'R6': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R6_depth.czi',\n",
    "        'R7': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R7_depth.czi',\n",
    "        'R8': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R8_depth.czi',\n",
    "        'R9': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R9_depth.czi',\n",
    "        'R10': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R10_depth.czi',\n",
    "        'R11': '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/20250928_change26pad_test_gel_R11_depth.czi',\n",
    "    },\n",
    "    \n",
    "    codebook_path = '/media/duan/sda2/MALDI/Data/20250928_Gel26Test/Test26.csv', # CodeBook路径，需为逗号分隔文件\n",
    "    output_path = 'Result', # 输出结果路径\n",
    "    anchor_channel = 'AF405', # 用于对齐的通道名称，默认为AF405。也可以替换为其它的。\n",
    "    \n",
    "    extra = None,\n",
    "    # 如果没有额外的轮，填写 extra = None或extra = {}等即可\n",
    "    # rRNA一定设置key为rRNA，其它的可以根据实际情况设置，例如P16，GFAP，MRC1...\n",
    "    # extra = {\n",
    "    #     'rRNA': {\n",
    "    #         'filepath': '/media/duan/DuanLab_Data/openFISH/Decode/TestData/20250118_P16_13M_58_V5_8_ABA109_GFP_rRNA_depth_new.czi',\n",
    "    #         'channel': ['AF405', 'AF546'] # 这里需要列出涉及到的通道名称\n",
    "    #     },\n",
    "    #     \"P16\": {\n",
    "    #         'filepath': '/media/duan/DuanLab_Data/openFISH/Decode/TestData/20250118_P16_13M_58_V5_8_ABA109_GFP_rRNA_depth.czi',\n",
    "    #         'channel': ['AF405', 'AF488'] # 这张图像有AF405，AF488，AF546三个通道，但是只需要前两个通道\n",
    "    #     }\n",
    "    # },\n",
    "    \n",
    "    run_deblur = True, # 是否运行去模糊，所有的extra图像会无视这个参数，都不运行去模糊\n",
    "    run_BaSiC = True, # 是否运行BaSiC用于去除小图阴影，非拼图无视这个参数，extra接受这个参数\n",
    "    objective = '20X', # 物镜倍率，影响通道间位移，像素点物理距离参数。可填任意参数，只要在translation_matrix和pixel_scaler提供对应的键即可\n",
    "    threads = 48, # 使用的线程数，最大不会超过电脑最大线程数-1\n",
    "    run_basic_clustering = False, # 在运行matrixization后是否进行简单的聚类分析，基因数大于60时无视这个参数，默认运行\n",
    "    \n",
    "    # 该程序设定了两个概念，procedure和progress；progress指的是每一轮，每一通道的处理情况，在output_path中的tmp文件夹中会生成一个yaml文件用于储存进度，\n",
    "    # 程序会自动根据yaml的情况在断点处运行。\n",
    "    # procedure指的是从图像预处理到生成表达矩阵的五个部分，每一个部分有对应的代号，可以跳过或强制运行\n",
    "    # 0: preprocess, 1: stitching&regietration, 2: point detection, 3: segmentation, 4: decoding, 5: matrixization\n",
    "    # 具体的使用例子见最后\n",
    "    skip_procedure = [3],\n",
    "    force_procedure = [0,1,2,4,5],\n",
    "   # 这些参数通常可以不用管，但如果某次实验有一些新的东西引入，可以按需修改\n",
    "    translation_matrix = {\n",
    "        \"20X\":{\n",
    "            \"DAPI\": [0.0, 0.0], \"AF405\": [0.0, 0.0], \"AF488\": [-0.38+5.38, 0.25], \"AF546\": [-3.61+5.38,0.12], \"AF594\": [5.38,0.0], \"Cy5\": [-2.54+5.38, -0.10], \"Cy7\": [-2.15+5.38,-0.39], \"DIC\": [5.38, 0.0]\n",
    "        },\n",
    "        \"40X\":{\n",
    "            \"DAPI\": [0.0 ,0.0], \"AF405\": [0.0, 0.0], \"AF488\": [-0.44, 0.85], \"AF546\": [-4.48, -0.03], \"AF594\": [0.0, 0.0], \"Cy5\": [-2.68, 0.28], \"Cy7\": [-1.94, -0.03]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    pixel_scaler = {\n",
    "        '20X': 0.325,\n",
    "        '40X': 0.1625\n",
    "    }\n",
    "    )\n",
    "\n",
    "\n",
    "OD = OpenDecoder(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1f1c4-fcc9-4257-beca-9204034ff675",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b><h2> 2.程序运行(已列出可以修改的参数)</b></h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb005314-904c-4e9d-b067-b6bd306c946c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Force run preporcess procedure\n",
      "\u001b[36;20m[INFO] (openDecode_Black.preprocess)\u001b[0m Preprocessing transcripts cycles\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [05:39<00:00, 30.86s/it]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Force run registration&stitching procedure\n",
      "\u001b[36;20m[INFO] (openDecode_Black.registration)\u001b[0m Trying MIST with ncc_threshod = 0.05\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [01:19<00:00,  1.55s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [01:13<00:00,  1.44s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:07<00:00,  7.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:02<00:00, 18.08it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.registration)\u001b[0m Registering tiles...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [13:18<00:00, 72.58s/it]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.registration)\u001b[0m Stitching tiles...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [03:04<00:00, 16.77s/it]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Force run spot detection procedure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spotiflow.model.spotiflow:Loading pretrained model: hybiss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running Spotiflow: R11_Cy7: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [16:12<00:00,  9.72s/it]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Skip segmentation procedure\n",
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Force run decoding procedure\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R1...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426182/426182 [00:05<00:00, 79520.82it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 128430/128430 [00:14<00:00, 9147.10it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R2...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 463713/463713 [00:04<00:00, 100637.98it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 157508/157508 [00:19<00:00, 7942.91it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R3...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 96806/96806 [00:01<00:00, 96031.83it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 27325/27325 [00:02<00:00, 9707.05it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R4...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 165702/165702 [00:01<00:00, 87459.41it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67299/67299 [00:08<00:00, 8224.17it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R5...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 445199/445199 [00:05<00:00, 85012.27it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 144039/144039 [00:16<00:00, 8830.93it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R6...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 97266/97266 [00:00<00:00, 106600.80it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 33118/33118 [00:04<00:00, 8003.96it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R7...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38292/38292 [00:00<00:00, 124755.83it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11083/11083 [00:01<00:00, 10280.62it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R8...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 330663/330663 [00:04<00:00, 82436.57it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112290/112290 [00:12<00:00, 8716.18it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R9...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 332630/332630 [00:03<00:00, 94222.08it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87182/87182 [00:09<00:00, 9027.91it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R10...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 824037/824037 [00:13<00:00, 62730.25it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 356793/356793 [00:36<00:00, 9683.06it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Decoding R11...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Preparing training set...\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 307366/307366 [00:03<00:00, 77739.29it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Training Random Forest Classifier...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Predicting spots...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.decoding)\u001b[0m Removing multi used spots...\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 102955/102955 [00:10<00:00, 9796.60it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Force run decoding procedure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m no axes information specified in the object, setting `dims` to: \u001b[1m(\u001b[0m\u001b[32m'c'\u001b[0m, \u001b[32m'y'\u001b[0m, \u001b[32m'x'\u001b[0m\u001b[1m)\u001b[0m                           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36;20m[INFO] (openDecode_Black.matrixization)\u001b[0m Resolving 49038 segmentation conflicts\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 49038/49038 [00:04<00:00, 9859.74it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.matrixization)\u001b[0m Fitering transcripts within distance  14.5 um...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.matrixization)\u001b[0m Aggregating transcripts into cell_boundaries\n",
      "\u001b[36;20m[INFO] (sopa.segmentation.aggregation)\u001b[0m Aggregating transcripts over 32416 cells\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 2.30 ss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36;20m[INFO] (openDecode_Black.matrixization)\u001b[0m Running basic clustering...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m The Zarr backing store has been changed from \u001b[3;35mNone\u001b[0m the new file path: Result/raw_sdata.zarr                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;20m[WARNING] (openDecode_Black.explorer.converter)\u001b[0m The cell IDs in the table or shapes are not valid Xenium Explorer IDs. They will be replaced by integers starting from 0 in the output files.\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.table)\u001b[0m Writing table with 57 columns\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.table)\u001b[0m Writing 1 cell/observations categories: region\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.shapes)\u001b[0m Writing 32416 cell polygons\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m Writing 1224631 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m    > Level 0: 1224631 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m    > Level 1: 306157 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m    > Level 2: 76539 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m    > Level 3: 19134 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m    > Level 4: 4783 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    (Loading image of shape (1, 11272, 16779)) in memory\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (1, 11272, 16779)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (1, 5636, 8389)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (1, 2818, 4194)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (1, 1409, 2097)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (1, 704, 1048)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (1, 352, 524)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.converter)\u001b[0m Saved files in the following directory: Result/Xenium_explorer\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.converter)\u001b[0m You can open the experiment with 'open Result/Xenium_explorer/experiment.xenium'\n"
     ]
    }
   ],
   "source": [
    "# 0\n",
    "OD.runPreprocess()\n",
    "# 1\n",
    "OD.runRegistration()\n",
    "\n",
    "# 2\n",
    "# 参数解释见https://weigertlab.org/spotiflow/api.html#spotiflow.model.spotiflow.Spotiflow.predict\n",
    "OD.runSpotiflow(\n",
    "    model_name = \"hybiss\",\n",
    "    intensity_threshold = {\n",
    "        'AF488': 100, 'AF546': 100, 'AF594': 100, 'Cy5': 100, 'Cy7': 100\n",
    "    },\n",
    "    prob_thresh = 0.40\n",
    ")\n",
    "\n",
    "# 3\n",
    "OD.runSegmentation(\n",
    "    # 参数解释见https://github.com/stardist/stardist\n",
    "    stardist_kwargs = {\n",
    "                            'prob_thresh': 0.5,\n",
    "                            'nms_thresh': 0.4,\n",
    "                            'trained_model': '2D_versatile_fluo',\n",
    "                            'sigma': 2.5\n",
    "                        },\n",
    "    # 参数解释见https://cellpose.readthedocs.io/en/latest/restore.html\n",
    "    cellpose_kwargs = {\n",
    "                            'restore_type': 'deblur_cyto3',\n",
    "                            'diameter': 45.,\n",
    "                            'flow_threshold': 1.,\n",
    "                            'cellprob_threshold': -6.,\n",
    "                        }\n",
    ")\n",
    "\n",
    "# 4\n",
    "# 先找出高置信点训练Ramdom Forest Classifier，然后用训练好的Model去预测所有点\n",
    "# 参数是优化过的，一般不需要更改\n",
    "OD.runDecoding(\n",
    "    # Training part\n",
    "    dist_threshold = 1.0, # 考虑两个点可能来自同一个RCP的最小距离(pixel)\n",
    "    prob_threshold = 0.2, # 考虑两个点可能来自同一个RCP的最小概率(Spotiflow的输出)差距\n",
    "    # Predicting part\n",
    "    prob_diff_threshold = 0.5,  # 同一个点可能预测出来后属于多个class，top1的class的概率至少比top2的大prob_diff_threshold才保留这个预测结果\n",
    "    qv_ratio_threshold = 0.85 # 如果一个点被多个组合使用则top1的qv值乘qv_ratio_threshold后需要比top2 qv值大，否则丢弃该点\n",
    ")\n",
    "\n",
    "# 5\n",
    "OD.runMatrixization(\n",
    "    buffer_radius = 3,  # 细胞核分割的buffer距离，单位为um\n",
    "    points_distance_threshold = 17.0, # 过滤点的距离参数，只有在没有细胞分割的时候有效，其它时候为细胞直径的平均数\n",
    ") # 该函数同时也用于生成Xenium Explorer文件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24942993-07b7-47e8-a7ba-1e1bb65f886d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b><h3>关于跳过步骤或强制执行步骤的example</b></h3>\n",
    "</div>\n",
    "\n",
    "| Procedure | Code |\n",
    "|:---------|:---------:|\n",
    "| preprocess | 0 |\n",
    "| registration | 1 |\n",
    "| spot detection | 2 |\n",
    "| segmentation | 3 |\n",
    "| decoding | 4 |\n",
    "| matrixization | 5 |\n",
    "\n",
    "___\n",
    "\n",
    "1.**假设一共11轮图像，今天拍了6轮，想先解码，也就是说你希望运行完解码即可，不用生成最终的表达矩阵，并且你希望下一次添加新的输入后不会重复运行**    \n",
    "    \n",
    "    第一次运行填写\n",
    "     filename = {\n",
    "        'R1': 'Demo_R1_depth.czi',\n",
    "        'R2': 'Demo_R2_depth.czi',\n",
    "        'R3': 'Demo_R3_depth.czi',\n",
    "        'R4': 'Demo_R4_depth.czi',\n",
    "        'R5': 'Demo_R5_depth.czi',\n",
    "        'R6': 'Demo_R6_depth.czi',\n",
    "    },\n",
    "    ...\n",
    "    skip_procedure: = [5], # 这里不跳过maxtrixization也是可以的\n",
    "    \n",
    "    第二次运行填写\n",
    "    filename = {\n",
    "        'R1': 'Demo_R1_depth.czi',\n",
    "        'R2': 'Demo_R2_depth.czi',\n",
    "        'R3': 'Demo_R3_depth.czi',\n",
    "        'R4': 'Demo_R4_depth.czi',\n",
    "        'R5': 'Demo_R5_depth.czi',\n",
    "        'R6': 'Demo_R6_depth.czi',\n",
    "        'R7': 'Demo_R7_depth.czi',\n",
    "        'R8': 'Demo_R8_depth.czi',\n",
    "        'R9': 'Demo_R9_depth.czi',\n",
    "        'R10': 'Demo_R10_depth.czi',\n",
    "        'R11': 'Demo_R11_depth.czi',\n",
    "    },\n",
    "    ...\n",
    "    skip_procedure: = []\n",
    "    \n",
    "2.**假设运行完全部程序后，你手动运行了某些图的信号点识别代码，你希望重新运行程序，你需要填写**     \n",
    "\n",
    "    skip_procedure = [0,1,2,3],\n",
    "    force_procedure = [4,5]\n",
    "    \n",
    "    *单独运行Spotiflow代码如下：\n",
    "    from openDecode.spotdetection import _run_single_spotiflow\n",
    "    from spotiflow.model import Spotiflow\n",
    "    import tifffile\n",
    "    \n",
    "    img = tifffile.imread(\"Demo_R1_Cy7.tif\")\n",
    "    \n",
    "    df = _run_single_spotiflow(img,\n",
    "                          model = Spotiflow.from_pretrained('hybiss'),\n",
    "                          intensity_threshold = 100,\n",
    "                          prob_thresh = 0.40,\n",
    "                          n_tiles = (5, 5),\n",
    "                          min_distance = 1, \n",
    "                          exclude_border = True,\n",
    "                          scale = None,\n",
    "                          subpix = True,\n",
    "                          peak_mode ='fast',\n",
    "                          normalizer = 'auto',\n",
    "                          verbose = True,\n",
    "                          device = 'cuda')\n",
    "                          \n",
    "    df.to_parquet(Demo_R1_Cy7.parquet)\n",
    "    \n",
    "3.**假设运行完全部程序后，你对片子进行了额外的抗体染色(GFAP)，你现在想添加进去，你需要填写**     \n",
    "\n",
    "    extra = {\n",
    "        'rRNA': {\n",
    "            'filepath': 'Demo_GFP_rRNA_depth_new.czi',\n",
    "            'channel': ['AF405', 'AF546'] \n",
    "        },\n",
    "        \"GFAP\": {\n",
    "            'filepath': 'Demo_GFAP_depth.czi',\n",
    "            'channel': ['AF405', 'Cy5'] \n",
    "        }\n",
    "    },\n",
    "    \n",
    "另外填写\n",
    "\n",
    "    skip_procedure = [2,3,4], # 不跳过5，因为根据progress.yaml文件，步骤5中的繁琐步骤会直接跳过，只用于生成带GFAP的Xenium Explorer文件\n",
    "    force_procedure = []\n",
    "    \n",
    "4.**假设运行完全部程序后，你想修改里面的一些参数后重新运行，可以按照以下的基本逻辑来决定**  \n",
    "\n",
    "    decoding依赖spot detection，所以重新运行spot detection后也一定重新运行decoding  \n",
    "    matrixization依赖decoding，所以重新运行decoding后也一定重新运行matrixization  \n",
    "\n",
    "        skip_procedure = [0,1,3],\n",
    "        force_procedure = [2,4,5]\n",
    "\n",
    "    matrixization同样也依赖segmentation，所以重新运行segmentation一定重新运行matrixization\n",
    "\n",
    "        skip_procedure = [0,1,2],\n",
    "        force_procedure = [3,5]\n",
    "\n",
    "    除filename和extra外，其它所有修改参数后运行都需要添加到force_procedure中，因为程序不会检测参数修改"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298a999-dd83-494f-86e7-bdc2c0fc9f96",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b><h3>一些补充说明</b></h3>\n",
    "</div>\n",
    "\n",
    "1. 如果最后生成的图片含有三个通道（例如DAPI, rRNA, GFP），Xenium Explorer默认会无视ome.tiff中的通道名称，在软件中显示R，G，B。但是可以通过在软件里再次add image的方法来方便图像查看，此时的图片会显示每个通道对应的名称。通道名称为你输入的extra的key + _ + 通道。例如 rRNA_AF546或GFAP_Cy5\n",
    "\n",
    "2. 结果文件含有Registration, Segmentation, tmp三个文件夹，和一个spatialdata(raw_sdata.zarr)文件，一个Xenium Explorer文件和一个Decoded_transcripts.parquet（储存着解码后的点的信息，其中有一列是qv值，代表着点的置信度，qv < 20意味着该点根据点与点之间的距离被标记了），和一个adata.h5ad文件。Registration中含有两个子文件夹分别用于储存拼接前和拼接后的图片，拼接前的图片以npy格式保存，拼接后图片以tiff格式保存，Spotiflow结果以parquet格式保存。另外根据输入还会生成1-3张morphology结果的tiff图片。Segmentation中含有细胞分割的结果。tmp文件夹中包含很多中间文件，方便断点开始或数据检查。\n",
    "\n",
    "3. 原始图像会进行简单的clip以去除过曝的点，然后会使用richardson_lucy进行deblur，psf是估算出来的Gaussian psf。然后正常运行BaSiC。\n",
    "    \n",
    "4. 图像拼接和对齐的方法没有改变，只是对齐的参数进行了一些调整，兼顾了速度和准确度。\n",
    "\n",
    "5. 信号点识别目前只保留的Spotiflow，**如果有需要**，我可以把RS-FISH也添加进来。\n",
    "\n",
    "6. 信号点的解码目前有两步，第一步选出置信度特别高的点用于训练随机森林模型，然后用这个模型去预测所有的点。如果只含有单色编码，那么就会直接将点转化成对应基因，把Spotiflow的最后结果prob * 40作为qv。\n",
    "\n",
    "7. 最后会生成表达矩阵并进行简单聚类(如果基因数大于60或者run_basic_clustering = True). rRNA和DAPI的分割依旧是按照rRNA为主，DAPI为辅的原则merge到一起。\n",
    "\n",
    "8. **再次强调，程序能够检测输入文件的更改，无法检测其它输入的更改，如果有函数参数发生改变等，请务必调整skip_procedure和force_procedure这两个参数。**\n",
    "\n",
    "9. 设置了不合理的skip_procedure和force_procedure程序会提示警告，所以仔细查看输出的字段。\n",
    "\n",
    "10. rRNA只支持两个通道输入，不要设置第三个通道，如果rRNA的图片含有其余通道的信息，可以将其设置为\n",
    "\n",
    "        extra = {\n",
    "            'rRNA': {\n",
    "                'filepath': '/media/duan/DuanLab_Data/openFISH/Decode/TestData/20250118_P16_13M_58_V5_8_ABA109_GFP_rRNA_depth_new.czi',\n",
    "                'channel': ['AF405', 'AF546'] # 这里需要列出涉及到的通道名称\n",
    "            },\n",
    "            \"Other\": {\n",
    "                'filepath': '/media/duan/DuanLab_Data/openFISH/Decode/TestData/20250118_P16_13M_58_V5_8_ABA109_GFP_rRNA_depth_new.czi',\n",
    "                'channel': ['AF405', 'AF488'] # 同样的图片，但是这次只需要AF405和AF488\n",
    "                \n",
    "\n",
    "10. *还有其它问题就问 xinyoung_li@genetics.ac.cn*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36beb32b-363d-4431-8703-88787dc2175d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b><h3>另外，如果需要运行多个notebook，为避免运行完占用内存/显存不释放，可以运行下面的代码</b></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1630a-1757-4733-9c5c-a0011fb0b550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effcaa42-ebe5-469d-8cd0-ee0cc241dce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sopa]",
   "language": "python",
   "name": "conda-env-sopa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
