{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92918799-2049-46a4-a542-2ac30086cb43",
   "metadata": {},
   "source": [
    "## 该Notebook是V13版本的OpenFISH decoding代码，openDecode的版本为V2.0 beta，特性如下：  \n",
    "\n",
    "* 接受的输入为depth后的czi文件；\n",
    "* 全程都可以在notebook内部完成 \n",
    "* 使用的包见 D:/openFISH/Decoding/openDecode\n",
    "* 主要包含图像预处理(preprocess)-图像对齐(registration)-信号点识别(spot detection)-细胞分割(segmentation)-解码(decoding)-生成表达矩阵(matrixization)五个部分\n",
    "* 以上五个部分有对应的‘代号’，可以用于跳过运行或强制运行.(具体的跳过或者强制运行命令见下)\n",
    "| Procedure | Code |\n",
    "|:---------|:---------:|\n",
    "| preprocess | 0 |\n",
    "| registration | 1 |\n",
    "| spot detection | 2 |\n",
    "| segmentation | 3 |\n",
    "| decoding | 4 |\n",
    "| matrixization | 5 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ef250-587c-4260-9ba8-17d50009f01a",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93864b32-db3e-42b9-a43b-aa327458417d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>提示：</b>拍图时不要设置通道位移参数， 拍图请仔细调整曝光时间和曝光强度，避免过曝，淬灭或过暗。拍图通道选择无要求，但需保证和CodeBook一致</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>提示：</b>请至少使用景深扩展处理图像，最好不要进行拼接(到位)，这样会使图像非马赛克化(is_mosiac = False)。但是该解码程序支持非拼图(包括单张小图或拼接好的大图)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6b44fe-6292-4d8c-b813-30483eb78f77",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b><h2> 1.填写参数</b></h2> \n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>提示:</b>CodeBook格式如下(逗号分隔)：</div>\n",
    "支持全单色编码，全双色编码，单双色混合编码\n",
    "\n",
    "| gene | RO1 | RO2 | Round |\n",
    "|---------:|---------:|---------:|---------:|\n",
    "| Cck | AF488 | AF546 | R1 |\n",
    "| Rgs5 | AF488 | AF594 | R1 |\n",
    "| Nfib | Cy5 | Cy5 | R1 |\n",
    "| Slc17a6 | AF546 | AF546 | R4 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a81eaf24-e236-4dcf-8f8e-41ecad010276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:/openFISH/Decoding\")\n",
    "\n",
    "from openDecode_Black import OpenDecoder, config\n",
    "\n",
    "para = config.Para(\n",
    "    \n",
    "    filename = {\n",
    "        'R1': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R1_depth.czi',\n",
    "        'R2': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R2_depth.czi',\n",
    "        'R3': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R3_depth.czi',\n",
    "        'R4': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R4_depth.czi',\n",
    "        'R5': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R5_depth.czi',\n",
    "        'R6': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R6_depth.czi',\n",
    "        'R7': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R7_depth.czi',\n",
    "        'R8': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R8_depth.czi',\n",
    "        'R9': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R9_depth.czi',\n",
    "        'R10': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R10_depth.czi',\n",
    "        'R11': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_R11_depth.czi',\n",
    "    },\n",
    "    \n",
    "    codebook_path = 'J:/WS/20251007_MALDI_DHB_10um/CodingBook.CSV', # CodeBook路径，需为逗号分隔文件\n",
    "    output_path = 'Result_9AA_5FAD', # 输出结果路径\n",
    "    anchor_channel = 'AF405', # 用于对齐的通道名称，默认为AF405。也可以替换为其它的。\n",
    "    \n",
    "    # extra = None,\n",
    "    # 如果没有额外的轮，填写 extra = None或extra = {}等即可\n",
    "    # rRNA一定设置key为rRNA，其它的可以根据实际情况设置，例如P16，GFAP，MRC1...\n",
    "    extra = {\n",
    "        # 'rRNA': {\n",
    "        #     'filepath': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_rRNA_depth.czi',\n",
    "        #     'channel': ['AF405', 'AF546'] # 这里需要列出涉及到的通道名称\n",
    "        # },\n",
    "         'DIC': {\n",
    "            'filepath': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_DIC_depth.czi',\n",
    "            'channel': ['AF405', 'DIC'] # 这里需要列出涉及到的通道名称\n",
    "        },\n",
    "        'Ablation': {\n",
    "            'filepath': 'J:/WS/20251126_9AA/20251126_MALDI_9AA_20um_8um_5FAD_A4_35_AF488_depth.czi',\n",
    "            'channel': ['AF405', 'AF488'] # 这里需要列出涉及到的通道名称\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    run_deblur = True, # 是否运行去模糊，所有的extra图像会无视这个参数，都不运行去模糊\n",
    "    run_BaSiC = True, # 是否运行BaSiC用于去除小图阴影，非拼图无视这个参数，extra接受这个参数\n",
    "    objective = '20X', # 物镜倍率，影响通道间位移，像素点物理距离参数。可填任意参数，只要在translation_matrix和pixel_scaler提供对应的键即可\n",
    "    threads = 40, # 使用的线程数，最大不会超过电脑最大线程数-1\n",
    "    run_basic_clustering = False, # 在运行matrixization后是否进行简单的聚类分析，基因数大于60时无视这个参数，默认运行\n",
    "    \n",
    "    # 该程序设定了两个概念，procedure和progress；progress指的是每一轮，每一通道的处理情况，在output_path中的tmp文件夹中会生成一个yaml文件用于储存进度，\n",
    "    # 程序会自动根据yaml的情况在断点处运行。\n",
    "    # procedure指的是从图像预处理到生成表达矩阵的五个部分，每一个部分有对应的代号，可以跳过或强制运行\n",
    "    # 0: preprocess, 1: stitching&regietration, 2: point detection, 3: segmentation, 4: decoding, 5: matrixization\n",
    "    # 具体的使用例子见最后\n",
    "    skip_procedure = [0,1,2,3,4],\n",
    "    force_procedure = [5],\n",
    "   # 这些参数通常可以不用管，但如果某次实验有一些新的东西引入，可以按需修改\n",
    "    translation_matrix = {\n",
    "        \"20X\":{\n",
    "            \"DAPI\": [0.0, 0.0], \"AF405\": [0.0, 0.0], \"AF488\": [-0.38+5.38, 0.25], \"AF546\": [-3.61+5.38,0.12], \"AF594\": [5.38,0.0], \"Cy5\": [-2.54+5.38, -0.10], \"Cy7\": [-2.15+5.38,-0.39], \"DIC\": [5.38, 0.0]\n",
    "        },\n",
    "        \"40X\":{\n",
    "            \"DAPI\": [0.0 ,0.0], \"AF405\": [0.0, 0.0], \"AF488\": [-0.44, 0.85], \"AF546\": [-4.48, -0.03], \"AF594\": [0.0, 0.0], \"Cy5\": [-2.68, 0.28], \"Cy7\": [-1.94, -0.03]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    pixel_scaler = {\n",
    "        '20X': 0.325,\n",
    "        '40X': 0.1625\n",
    "    }\n",
    "    )\n",
    "\n",
    "\n",
    "OD = OpenDecoder(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1f1c4-fcc9-4257-beca-9204034ff675",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b><h2> 2.程序运行(已列出可以修改的参数)</b></h2> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb005314-904c-4e9d-b067-b6bd306c946c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Skip preporcess procedure\n",
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Skip registration&stitching procedure\n",
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Skip spot detection procedure\n",
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Skip segmentation procedure\n",
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Skip decoding procedure\n",
      "\u001b[36;20m[INFO] (openDecode_Black.main)\u001b[0m Force run matrixization procedure\n",
      "\u001b[36;20m[INFO] (openDecode_Black.matrixization)\u001b[0m Resolving 62424 segmentation conflicts\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 62424/62424 [00:12<00:00, 4856.27it/s]\n",
      "\u001b[36;20m[INFO] (openDecode_Black.matrixization)\u001b[0m Fitering transcripts within distance  13.3 um...\n",
      "\u001b[36;20m[INFO] (openDecode_Black.matrixization)\u001b[0m Aggregating transcripts into cell_boundaries\n",
      "\u001b[36;20m[INFO] (sopa.segmentation.aggregation)\u001b[0m Aggregating transcripts over 45500 cells\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 11.24 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36;20m[INFO] (openDecode_Black.matrixization)\u001b[0m Running basic clustering...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m The Zarr backing store has been changed from \u001b[3;35mNone\u001b[0m the new file path: Result_9AA_5FAD\\raw_sdata.zarr       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33;20m[WARNING] (openDecode_Black.explorer.converter)\u001b[0m The cell IDs in the table or shapes are not valid Xenium Explorer IDs. They will be replaced by integers starting from 0 in the output files.\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.table)\u001b[0m Writing table with 110 columns\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.table)\u001b[0m Writing 2 cell/observations categories: region, leiden\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.shapes)\u001b[0m Writing 45500 cell polygons\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m Writing 5098157 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m    > Level 0: 5098157 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m    > Level 1: 1274539 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m    > Level 2: 318634 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m    > Level 3: 79658 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.points)\u001b[0m    > Level 4: 19914 transcripts\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m Writing multiscale image with procedure=semi-lazy (load in memory when possible)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    (Loading image of shape (4, 18627, 16769)) in memory\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (4, 18627, 16769)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (4, 9313, 8384)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (4, 4656, 4192)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (4, 2328, 2096)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (4, 1164, 1048)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.images)\u001b[0m    > Image of shape (4, 582, 524)\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.converter)\u001b[0m Saved files in the following directory: Result_9AA_5FAD\\Xenium_explorer\n",
      "\u001b[36;20m[INFO] (openDecode_Black.explorer.converter)\u001b[0m You can open the experiment with 'open Result_9AA_5FAD\\Xenium_explorer\\experiment.xenium'\n"
     ]
    }
   ],
   "source": [
    "# 0\n",
    "OD.runPreprocess()\n",
    "# 1\n",
    "OD.runRegistration()\n",
    "\n",
    "# 2\n",
    "# 参数解释见https://weigertlab.org/spotiflow/api.html#spotiflow.model.spotiflow.Spotiflow.predict\n",
    "OD.runSpotiflow(\n",
    "    model_name = \"hybiss\",\n",
    "    intensity_threshold = {\n",
    "        'AF488': 100, 'AF546': 100, 'AF594': 100, 'Cy5': 100, 'Cy7': 100\n",
    "    },\n",
    "    prob_thresh = 0.40\n",
    ")\n",
    "\n",
    "# 3\n",
    "OD.runSegmentation(\n",
    "    # 参数解释见https://github.com/stardist/stardist\n",
    "    stardist_kwargs = {\n",
    "                            'prob_thresh': 0.5,\n",
    "                            'nms_thresh': 0.4,\n",
    "                            'trained_model': '2D_versatile_fluo',\n",
    "                            'sigma': 2.5\n",
    "                        },\n",
    "    # 参数解释见https://cellpose.readthedocs.io/en/latest/restore.html\n",
    "    cellpose_kwargs = {\n",
    "                            'restore_type': 'deblur_cyto3',\n",
    "                            'diameter': 45.,\n",
    "                            'flow_threshold': 1.,\n",
    "                            'cellprob_threshold': -6.,\n",
    "                        }\n",
    ")\n",
    "\n",
    "# 4\n",
    "# 先找出高置信点训练Ramdom Forest Classifier，然后用训练好的Model去预测所有点\n",
    "# 参数是优化过的，一般不需要更改\n",
    "OD.runDecoding(\n",
    "    # Training part\n",
    "    dist_threshold = 1.0, # 考虑两个点可能来自同一个RCP的最小距离(pixel)\n",
    "    prob_threshold = 0.2, # 考虑两个点可能来自同一个RCP的最小概率(Spotiflow的输出)差距\n",
    "    # Predicting part\n",
    "    prob_diff_threshold = 0.5,  # 同一个点可能预测出来后属于多个class，top1的class的概率至少比top2的大prob_diff_threshold才保留这个预测结果\n",
    "    qv_ratio_threshold = 0.85 # 如果一个点被多个组合使用则top1的qv值乘qv_ratio_threshold后需要比top2 qv值大，否则丢弃该点\n",
    ")\n",
    "\n",
    "# 5\n",
    "OD.runMatrixization(\n",
    "    buffer_radius = 1,  # 细胞核分割的buffer距离，单位为um\n",
    "    points_distance_threshold = 17.0, # 过滤点的距离参数，只有在没有细胞分割的时候有效，其它时候为细胞直径的平均数\n",
    ") # 该函数同时也用于生成Xenium Explorer文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df67cd7-f307-4369-84d7-370112f2f8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24942993-07b7-47e8-a7ba-1e1bb65f886d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b><h3>关于跳过步骤或强制执行步骤的example</b></h3>\n",
    "</div>\n",
    "\n",
    "| Procedure | Code |\n",
    "|:---------|:---------:|\n",
    "| preprocess | 0 |\n",
    "| registration | 1 |\n",
    "| spot detection | 2 |\n",
    "| segmentation | 3 |\n",
    "| decoding | 4 |\n",
    "| matrixization | 5 |\n",
    "\n",
    "___\n",
    "\n",
    "1.**假设一共11轮图像，今天拍了6轮，想先解码，也就是说你希望运行完解码即可，不用生成最终的表达矩阵，并且你希望下一次添加新的输入后不会重复运行**    \n",
    "    \n",
    "    第一次运行填写\n",
    "     filename = {\n",
    "        'R1': 'Demo_R1_depth.czi',\n",
    "        'R2': 'Demo_R2_depth.czi',\n",
    "        'R3': 'Demo_R3_depth.czi',\n",
    "        'R4': 'Demo_R4_depth.czi',\n",
    "        'R5': 'Demo_R5_depth.czi',\n",
    "        'R6': 'Demo_R6_depth.czi',\n",
    "    },\n",
    "    ...\n",
    "    skip_procedure: = [5], # 这里不跳过maxtrixization也是可以的\n",
    "    \n",
    "    第二次运行填写\n",
    "    filename = {\n",
    "        'R1': 'Demo_R1_depth.czi',\n",
    "        'R2': 'Demo_R2_depth.czi',\n",
    "        'R3': 'Demo_R3_depth.czi',\n",
    "        'R4': 'Demo_R4_depth.czi',\n",
    "        'R5': 'Demo_R5_depth.czi',\n",
    "        'R6': 'Demo_R6_depth.czi',\n",
    "        'R7': 'Demo_R7_depth.czi',\n",
    "        'R8': 'Demo_R8_depth.czi',\n",
    "        'R9': 'Demo_R9_depth.czi',\n",
    "        'R10': 'Demo_R10_depth.czi',\n",
    "        'R11': 'Demo_R11_depth.czi',\n",
    "    },\n",
    "    ...\n",
    "    skip_procedure: = []\n",
    "    \n",
    "2.**假设运行完全部程序后，你手动运行了某些图的信号点识别代码，你希望重新运行程序，你需要填写**     \n",
    "\n",
    "    skip_procedure = [0,1,2,3],\n",
    "    force_procedure = [4,5]\n",
    "    \n",
    "    *单独运行Spotiflow代码如下：\n",
    "    from openDecode.spotdetection import _run_single_spotiflow\n",
    "    from spotiflow.model import Spotiflow\n",
    "    import tifffile\n",
    "    \n",
    "    img = tifffile.imread(\"Demo_R1_Cy7.tif\")\n",
    "    \n",
    "    df = _run_single_spotiflow(img,\n",
    "                          model = Spotiflow.from_pretrained('hybiss'),\n",
    "                          intensity_threshold = 100,\n",
    "                          prob_thresh = 0.40,\n",
    "                          n_tiles = (5, 5),\n",
    "                          min_distance = 1, \n",
    "                          exclude_border = True,\n",
    "                          scale = None,\n",
    "                          subpix = True,\n",
    "                          peak_mode ='fast',\n",
    "                          normalizer = 'auto',\n",
    "                          verbose = True,\n",
    "                          device = 'cuda')\n",
    "                          \n",
    "    df.to_parquet(Demo_R1_Cy7.parquet)\n",
    "    \n",
    "3.**假设运行完全部程序后，你对片子进行了额外的抗体染色(GFAP)，你现在想添加进去，你需要填写**     \n",
    "\n",
    "    extra = {\n",
    "        'rRNA': {\n",
    "            'filepath': 'Demo_GFP_rRNA_depth_new.czi',\n",
    "            'channel': ['AF405', 'AF546'] \n",
    "        },\n",
    "        \"GFAP\": {\n",
    "            'filepath': 'Demo_GFAP_depth.czi',\n",
    "            'channel': ['AF405', 'Cy5'] \n",
    "        }\n",
    "    },\n",
    "    \n",
    "另外填写\n",
    "\n",
    "    skip_procedure = [2,3,4], # 不跳过5，因为根据progress.yaml文件，步骤5中的繁琐步骤会直接跳过，只用于生成带GFAP的Xenium Explorer文件\n",
    "    force_procedure = []\n",
    "    \n",
    "4.**假设运行完全部程序后，你想修改里面的一些参数后重新运行，可以按照以下的基本逻辑来决定**  \n",
    "\n",
    "    decoding依赖spot detection，所以重新运行spot detection后也一定重新运行decoding  \n",
    "    matrixization依赖decoding，所以重新运行decoding后也一定重新运行matrixization  \n",
    "\n",
    "        skip_procedure = [0,1,3],\n",
    "        force_procedure = [2,4,5]\n",
    "\n",
    "    matrixization同样也依赖segmentation，所以重新运行segmentation一定重新运行matrixization\n",
    "\n",
    "        skip_procedure = [0,1,2],\n",
    "        force_procedure = [3,5]\n",
    "\n",
    "    除filename和extra外，其它所有修改参数后运行都需要添加到force_procedure中，因为程序不会检测参数修改"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298a999-dd83-494f-86e7-bdc2c0fc9f96",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b><h3>一些补充说明</b></h3>\n",
    "</div>\n",
    "\n",
    "1. 如果最后生成的图片含有三个通道（例如DAPI, rRNA, GFP），Xenium Explorer默认会无视ome.tiff中的通道名称，在软件中显示R，G，B。但是可以通过在软件里再次add image的方法来方便图像查看，此时的图片会显示每个通道对应的名称。通道名称为你输入的extra的key + _ + 通道。例如 rRNA_AF546或GFAP_Cy5\n",
    "\n",
    "2. 结果文件含有Registration, Segmentation, tmp三个文件夹，和一个spatialdata(raw_sdata.zarr)文件，一个Xenium Explorer文件和一个Decoded_transcripts.parquet（储存着解码后的点的信息，其中有一列是qv值，代表着点的置信度，qv < 20意味着该点根据点与点之间的距离被标记了），和一个adata.h5ad文件。Registration中含有两个子文件夹分别用于储存拼接前和拼接后的图片，拼接前的图片以npy格式保存，拼接后图片以tiff格式保存，Spotiflow结果以parquet格式保存。另外根据输入还会生成1-3张morphology结果的tiff图片。Segmentation中含有细胞分割的结果。tmp文件夹中包含很多中间文件，方便断点开始或数据检查。\n",
    "\n",
    "3. 原始图像会进行简单的clip以去除过曝的点，然后会使用richardson_lucy进行deblur，psf是估算出来的Gaussian psf。然后正常运行BaSiC。\n",
    "    \n",
    "4. 图像拼接和对齐的方法没有改变，只是对齐的参数进行了一些调整，兼顾了速度和准确度。\n",
    "\n",
    "5. 信号点识别目前只保留的Spotiflow，**如果有需要**，我可以把RS-FISH也添加进来。\n",
    "\n",
    "6. 信号点的解码目前有两步，第一步选出置信度特别高的点用于训练随机森林模型，然后用这个模型去预测所有的点。如果只含有单色编码，那么就会直接将点转化成对应基因，把Spotiflow的最后结果prob * 40作为qv。\n",
    "\n",
    "7. 最后会生成表达矩阵并进行简单聚类(如果基因数大于60或者run_basic_clustering = True). rRNA和DAPI的分割依旧是按照rRNA为主，DAPI为辅的原则merge到一起。\n",
    "\n",
    "8. **再次强调，程序能够检测输入文件的更改，无法检测其它输入的更改，如果有函数参数发生改变等，请务必调整skip_procedure和force_procedure这两个参数。**\n",
    "\n",
    "9. 设置了不合理的skip_procedure和force_procedure程序会提示警告，所以仔细查看输出的字段。\n",
    "\n",
    "10. rRNA只支持两个通道输入，不要设置第三个通道，如果rRNA的图片含有其余通道的信息，可以将其设置为\n",
    "\n",
    "        extra = {\n",
    "            'rRNA': {\n",
    "                'filepath': '/media/duan/DuanLab_Data/openFISH/Decode/TestData/20250118_P16_13M_58_V5_8_ABA109_GFP_rRNA_depth_new.czi',\n",
    "                'channel': ['AF405', 'AF546'] # 这里需要列出涉及到的通道名称\n",
    "            },\n",
    "            \"Other\": {\n",
    "                'filepath': '/media/duan/DuanLab_Data/openFISH/Decode/TestData/20250118_P16_13M_58_V5_8_ABA109_GFP_rRNA_depth_new.czi',\n",
    "                'channel': ['AF405', 'AF488'] # 同样的图片，但是这次只需要AF405和AF488\n",
    "                \n",
    "\n",
    "10. *还有其它问题就问 xinyoung_li@genetics.ac.cn*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36beb32b-363d-4431-8703-88787dc2175d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b><h3>另外，如果需要运行多个notebook，为避免运行完占用内存/显存不释放，可以运行下面的代码</b></h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1630a-1757-4733-9c5c-a0011fb0b550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    cp.get_default_memory_pool().free_all_blocks()\n",
    "    cp.get_default_pinned_memory_pool().free_all_blocks()\n",
    "\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        \n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effcaa42-ebe5-469d-8cd0-ee0cc241dce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sopa]",
   "language": "python",
   "name": "conda-env-sopa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
